{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kikjeck1/Final-project-DS/blob/master/tink_NLP_model(text_generation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель получилась не оформленной. Помешал недостаток опыта работы с NLP моделями, нейросетями и с сохранением модели. Я использую для обучения статьи английской википедии, так как модель потребляет очень много памяти приходится её учить не на самых больших объёмах. У класса метод fit() работает хорошо. У метода train есть параметр method от чего реализуется либо k-gramm способ генерации либо k-gramm + classic ML. Модель получилась не очень гибкой и желательно задавать ровно 3 стартовых слова. Пример обучения и кода приведён ниже, под кодом модели. "
      ],
      "metadata": {
        "id": "rraWCJQ8TS-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OSqyZklL0-Dk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"wikipedia\", \"20220301.simple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "15e682140e2246a981c511a98888a511",
            "0350b389411742e596630d6ae76796dd",
            "823820d8f1a542e3a840d66d783d2625",
            "2a1566ad45d54671bb951ac904bffa64",
            "2c52950500f949f69bb62e8f2094520a",
            "f838fe1fd7ad4757a95b9d1ec4d0603f",
            "dbbb5739e5d843f680e21a135d790250",
            "2b6892c06956434181e6fb46d64a3b0d",
            "ff42a1b09a1745e1940720d06360479e",
            "b0cf913ef11b472d9b64cf6a813905dc",
            "9864e97ab1fb453a90bbeb03afa51154"
          ]
        },
        "id": "i2sySA5KJpWr",
        "outputId": "6e92d5d1-6dc7-4057-f1f5-99a33ba4f511"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset wikipedia (/root/.cache/huggingface/datasets/wikipedia/20220301.simple/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15e682140e2246a981c511a98888a511"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Word2Vec(sentences=snts, size=100, window=10, min_count=10)\n",
        "\n",
        "\n",
        "class NLP_model:\n",
        "  \"\"\"\n",
        "  init\n",
        "  fit\n",
        "  generate\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.d = None\n",
        "    self.v2w_model = None\n",
        "    self.snts = None\n",
        "\n",
        "  def fit(self, text):\n",
        "\n",
        "    def tokenize(text, nump=False):\n",
        "      sentences = []\n",
        "\n",
        "      for art in text:\n",
        "        # snts = re.split(\";|.|!|?\", art)\n",
        "        snts = art.split('.')\n",
        "    #     print(snts)\n",
        "        for snt in snts:\n",
        "          if snt != '': sentences.append(snt.strip())\n",
        "\n",
        "      # print(sentences5[:10])\n",
        "      for i in range(len(sentences)):\n",
        "        snt = sentences[i].split()\n",
        "        a = []\n",
        "        for w in snt:\n",
        "          c = w.rstrip(' ' + punctuation).lower().lstrip(' ' + punctuation)\n",
        "          if c != '':\n",
        "            a.append(c)\n",
        "\n",
        "        # a.append(\".\") #!!!!!!\n",
        "        if nump:\n",
        "          sentences[i] = np.array(a) # add type of string??\n",
        "        else:\n",
        "          sentences[i] = a\n",
        "      if nump:\n",
        "        return np.array(sentences)\n",
        "      else:\n",
        "        return sentences\n",
        "\n",
        "\n",
        "    def kgramm(k: int, sentences: list) -> dict:\n",
        "    \n",
        "      dt = dict()\n",
        "      for snt in sentences:\n",
        "          if len(snt) <= k:\n",
        "              continue\n",
        "          \n",
        "          grams = np.lib.stride_tricks.sliding_window_view(snt, k)\n",
        "          for i in range(len(grams) - 1):\n",
        "              tup = tuple(grams[i])\n",
        "              if tup not in dt:\n",
        "                  dt[tup] = {grams[i+1][-1] : 1}\n",
        "              else:\n",
        "                  if grams[i+1][-1] in dt[tup]:\n",
        "                      dt[tup][grams[i+1][-1]] += 1\n",
        "                  else:\n",
        "                      dt[tup][grams[i+1][-1]] = 1\n",
        "                  \n",
        "      return dt\n",
        "\n",
        "    self.snts = tokenize(text)\n",
        "    self.d = [kgramm(i, self.snts[:10**5]) for i in range(3, 0, -1)]\n",
        "    self.v2w_model = Word2Vec(sentences=self.snts[:10**5], size=40, window=5, min_count=0)\n",
        "\n",
        "\n",
        "  def generate(self, prefix=[\"it\", \"was\", \"a\"], method=\"kgramm\", n_words = 5):\n",
        "\n",
        "    def test(d, words, n=5):\n",
        "      # level = len(words)\n",
        "      last = tuple(words)\n",
        "      print(*last)\n",
        "      j = 0\n",
        "      i = 0\n",
        "      while i < n:\n",
        "        try:\n",
        "          values = np.fromiter(d[j][last[j:]].values(), dtype=int)\n",
        "          prob = values / np.sum(values)\n",
        "          a = np.fromiter(d[j][last[j:]].keys(), dtype=\"U16\")\n",
        "          last = (*last[1:], np.random.choice(a, p=prob))\n",
        "          # print(last[-1],f\"({3-j})\", end=\" \")\n",
        "          print(last[-1], end=\" \")\n",
        "          i += 1\n",
        "        except KeyError:\n",
        "          j += 1\n",
        "          if j == 3:\n",
        "            raise ValueError(\"Модель не может подобрать продолжение.\\\n",
        "            Попробуйте ещё раз или измените префикc.\")\n",
        "\n",
        "    def ngramm_forest(dcts,snts, start=prefix, word_pos=4):\n",
        "      # tail = start.split()\n",
        "      tail = start\n",
        "      model = self.v2w_model\n",
        "      gram_ind = 0\n",
        "      d = dcts\n",
        "      if tuple(tail) not in d[gram_ind]:\n",
        "        tail = tail[1:]\n",
        "        gram_ind += 1\n",
        "      \n",
        "      # print(tail)\n",
        "      # print(gram_ind)\n",
        "      b = np.array(sorted(d[gram_ind][tuple(tail)].items(), key=lambda x: x[1], reverse=True)[:3])\n",
        "      st = set(b[:, 0])\n",
        "      a = []\n",
        "      for snt in snts[:10**5]: # np random choice in case of too long working time\n",
        "        if len(a) > 5000:\n",
        "            break\n",
        "        for i in range(3, len(snt)):\n",
        "          if snt[i] in st and tail[0] != snt[i-3 + gram_ind]:\n",
        "            a.append([*model.wv[snt[i-3]],\n",
        "                    len(snt[i-3]),\n",
        "                    *model.wv[snt[i-2]],\n",
        "                    len(snt[i-2]),\n",
        "                    *model.wv[snt[i-1]],\n",
        "                    len(snt[i-1]),\n",
        "                    i,\n",
        "                    snt[i]])\n",
        "        \n",
        "      a = np.array(a)\n",
        "      # print(a.shape)\n",
        "      # print(a[:4, :])\n",
        "      X = np.delete(a, -1, 1)\n",
        "      y = a[:, -1]\n",
        "      le = LabelEncoder()\n",
        "      le.fit(y)\n",
        "      y = le.transform(y)\n",
        "      # print(\"started fitting the model\")\n",
        "      forest = RandomForestClassifier(max_depth=5, random_state=0, n_estimators=10)\n",
        "      forest.fit(X, y)\n",
        "      next_word = le.inverse_transform(forest.predict([[*model.wv[prefix[0]],\n",
        "                  len(prefix[0]),\n",
        "                  *model.wv[prefix[1]],\n",
        "                  len(prefix[1]),\n",
        "                  *model.wv[prefix[2]],\n",
        "                  len(prefix[2]),\n",
        "                  word_pos]]))[0]\n",
        "      return next_word\n",
        "\n",
        "\n",
        "    if method == \"kgramm\":\n",
        "      test(self.d, words=prefix, n=n_words)\n",
        "    elif method == \"forest\":\n",
        "      tail = prefix\n",
        "      print(*tail, end=\" \")\n",
        "      for i in range(n_words):\n",
        "        next = ngramm_forest(self.d, snts=self.snts, start=tail, word_pos=4+i)\n",
        "        print(next, end=\" \")\n",
        "        tail = [*tail[1:], next]\n",
        "    else:\n",
        "      raise KeyError\n",
        "    "
      ],
      "metadata": {
        "id": "jLx9tYo517I3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod = NLP_model()\n",
        "text = ds[\"train\"][\"text\"]\n",
        "mod.fit(text)"
      ],
      "metadata": {
        "id": "_ewSfjcz_aDa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod.generate(method=\"forest\", prefix=[\"he\", \"could\", \"build\"], n_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51vEnPTrAXXT",
        "outputId": "161a4d9d-c4d3-4d0f-d511-d98e40bdf2a7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he could build a bridge because the water is about 30 meters deep "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod.generate(method=\"kgramm\", prefix=[\"he\", \"could\", \"build\"], n_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHM0QJIvTN0h",
        "outputId": "639c53e9-adf0-49ea-b162-70e6f2bf06b5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he could build\n",
            "a heavy smoker george died of cold and wet things "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AuH_OjwK04oh"
      },
      "outputs": [],
      "source": [
        "# def test(d, words, n=5):\n",
        "#   # level = len(words)\n",
        "#   last = tuple(words.split())\n",
        "#   print(*last)\n",
        "#   j = 0\n",
        "#   i = 0\n",
        "#   while i < n:\n",
        "#     try:\n",
        "#       values = np.fromiter(d[j][last[j:]].values(), dtype=int)\n",
        "#       prob = values / np.sum(values)\n",
        "#       a = np.fromiter(d[j][last[j:]].keys(), dtype=\"U16\")\n",
        "#       last = (*last[1:], np.random.choice(a, p=prob))\n",
        "#       print(last[-1],f\"({3-j})\", end=\" \")\n",
        "#       i += 1\n",
        "#     except KeyError:\n",
        "#       j += 1\n",
        "#       if j == 3:\n",
        "#         raise ValueError(\"Модель не может подобрать продолжение. Попробуйте ещё раз или измените префикc.\")\n",
        "\n",
        "        \n",
        "        \n",
        "# def kgramm(k: int, sentences: list) -> dict:\n",
        "    \n",
        "#   dt = dict()\n",
        "#   for snt in sentences:\n",
        "#       if len(snt) <= k:\n",
        "#           continue\n",
        "      \n",
        "#       grams = np.lib.stride_tricks.sliding_window_view(snt, k)\n",
        "#       for i in range(len(grams) - 1):\n",
        "#           tup = tuple(grams[i])\n",
        "#           if tup not in dt:\n",
        "#               dt[tup] = {grams[i+1][-1] : 1}\n",
        "#           else:\n",
        "#               if grams[i+1][-1] in dt[tup]:\n",
        "#                   dt[tup][grams[i+1][-1]] += 1\n",
        "#               else:\n",
        "#                   dt[tup][grams[i+1][-1]] = 1\n",
        "#   return dt\n",
        "\n",
        "# def tokenize(text, nump=True):\n",
        "#   sentences = []\n",
        "\n",
        "#   for art in text:\n",
        "#     # snts = re.split(\";|.|!|?\", art)\n",
        "#     snts = art.split('.')\n",
        "# #     print(snts)\n",
        "#     for snt in snts:\n",
        "#       if snt != '': sentences.append(snt.strip())\n",
        "\n",
        "#   # print(sentences5[:10])\n",
        "#   for i in range(len(sentences)):\n",
        "#     snt = sentences[i].split()\n",
        "#     a = []\n",
        "#     for w in snt:\n",
        "#       c = w.rstrip(' ' + punctuation).lower().lstrip(' ' + punctuation)\n",
        "#       if c != '':\n",
        "#         a.append(c)\n",
        "\n",
        "#     # a.append(\".\") #!!!!!!\n",
        "#     if nump:\n",
        "#       sentences[i] = np.array(a) # add type of string??\n",
        "#     else:\n",
        "#       sentences[i] = a\n",
        "#   if nump:\n",
        "#     return np.array(sentences)\n",
        "#   else:\n",
        "#     return sentences\n",
        "\n",
        "# def extract_features(sentences, model): # word2vec model\n",
        "#   features = []\n",
        "#   for snt in sentences:\n",
        "#     if len(snt) <= 3:\n",
        "#       continue\n",
        "    \n",
        "    \n",
        "#     for i in range(3, len(snt)):\n",
        "#       row = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P3y52fr61AB1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUBLN0mLcNUK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "j5bucJXr1DGX"
      },
      "outputs": [],
      "source": [
        "# text = ds[\"train\"][\"text\"]\n",
        "# # sentences = tokenize(text)\n",
        "# # sentences[:2]\n",
        "# text = ds[\"train\"][\"text\"]\n",
        "# snts = tokenize(text, nump=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# snts[0]"
      ],
      "metadata": {
        "id": "G_ze4jLMxZa2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YZtCoeEW1Wyl"
      },
      "outputs": [],
      "source": [
        "# d = [kgramm(i, np.random.choice(sentences, size=10**5)) for i in range(3, 0, -1)]\n",
        "# d = [kgramm(i, snts[:2*10**5]) for i in range(3, 0, -1)]\n",
        "# d = [kgramm(3, snts[:2*10**5]),]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# d[0][tuple(\"on the same\".split())].items()\n",
        "# b = np.array(sorted(d[0][tuple(\"on the same\".split())].items(), key=lambda x: x[1], reverse=True)[:3])\n",
        "# set(b[:, 0])\n",
        "# d.append()"
      ],
      "metadata": {
        "id": "K25PcRctcJ3L"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(4):\n",
        "#   test(d, \"it was a\", n = 10)\n",
        "#   print()"
      ],
      "metadata": {
        "id": "3CsZcmAwyGEC"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xGwX4_SbUe2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9hN-OtHG16L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gensim\n",
        "# from gensim.models.word2vec import Word2Vec\n",
        "# model = Word2Vec(sentences=snts, size=100, window=10, min_count=10)\n",
        "# model = Word2Vec(sentences=snts[:2*10**5], size=40, window=5, min_count=0)\n"
      ],
      "metadata": {
        "id": "OutkqO5VEWR4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gensim.models.word2vec import Word2Vec\n",
        "# model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "dn7TzPXsuJQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from gensim.models.word2vec import Word2Vec\n",
        "# model = Word2Vec.load(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "6UHvTTQhuJWq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tail = [\"it\", \"was\", \"a\"]\n",
        "# b = np.array(sorted(d[0][tuple(tail)].items(), key=lambda x: x[1], reverse=True))[:3]\n",
        "# model[\".\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAzo_wjBxPt3",
        "outputId": "88fffbfa-4836-4d56-ca5d-1e346d50ed57"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.19890684, -1.261631  ,  0.04040638, -1.4906827 , -1.7610592 ,\n",
              "       -1.1968117 ,  1.4301373 ,  1.5252349 ,  0.619835  , -1.0439737 ,\n",
              "        3.0477262 ,  1.837472  ,  2.5491025 ,  0.96900696,  1.9693129 ,\n",
              "        0.38344952, -0.06435214, -0.5196934 , -0.6399106 ,  0.4739755 ,\n",
              "        3.0627694 , -1.2734512 ,  0.7570529 , -0.02657134, -0.41007715,\n",
              "       -1.9053028 ,  2.0340095 ,  0.83900607,  4.1440396 ,  2.472197  ,\n",
              "        0.6530064 ,  2.3352132 , -1.1873986 ,  0.43339884, -2.5698922 ,\n",
              "       -0.60294354,  1.7513331 , -1.1444054 ,  1.3005747 ,  2.719398  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhqF57GVHUkr"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# import gc\n",
        "\n",
        "# def ngramm_forest(dcts, start=[\"it\", \"was\", \"a\"]):\n",
        "#   # tail = start.split()\n",
        "#   tail = start\n",
        "\n",
        "#   gram_ind = 0\n",
        "#   d = dcts\n",
        "#   if tuple(tail) not in d[gram_ind]:\n",
        "#     tail = tail[1:]\n",
        "#     gram_ind += 1\n",
        "  \n",
        "#   print(tail)\n",
        "#   print(gram_ind)\n",
        "#   b = np.array(sorted(d[gram_ind][tuple(tail)].items(), key=lambda x: x[1], reverse=True)[:3])\n",
        "#   st = set(b[:, 0])\n",
        "#   a = []\n",
        "#   for snt in snts[:2*10**5]: # np random choice in case of too long working time\n",
        "#     if len(a) > 5000:\n",
        "#         break\n",
        "#     for i in range(3 - gram_ind, len(snt)):\n",
        "#       if snt[i] in st and tail[0] != snt[i-3 + gram_ind]:\n",
        "#         a.append([*model.wv[snt[i-3]],\n",
        "#                 len(snt[i-3]),\n",
        "#                 *model.wv[snt[i-2]],\n",
        "#                 len(snt[i-2]),\n",
        "#                 *model.wv[snt[i-1]],\n",
        "#                 len(snt[i-1]),\n",
        "#                 i,\n",
        "#                 snt[i]])\n",
        "    \n",
        "#   a = np.array(a)\n",
        "#   # print(a.shape)\n",
        "#   # print(a[:4, :])\n",
        "#   X = np.delete(a, -1, 1)\n",
        "#   y = a[:, -1]\n",
        "#   le = LabelEncoder()\n",
        "#   le.fit(y)\n",
        "#   y = le.transform(y)\n",
        "#   # print(\"started fitting the model\")\n",
        "#   forest = RandomForestClassifier(max_depth=5, random_state=0, n_estimators=10)\n",
        "#   forest.fit(X, y)\n",
        "\n",
        "#   next_word = le.inverse_transform(forest.predict([[*model.wv[tail[0]],\n",
        "#               len(tail[0]),\n",
        "#               *model.wv[tail[1]],\n",
        "#               len(tail[1]),\n",
        "#               *model.wv[tail[2]],\n",
        "#               len(tail[2]),\n",
        "#               4]]))[0]\n",
        "#   return next_word\n",
        "\n",
        "#   # start = [*start[1:],next_word]\n",
        "#   # gc.collect()\n",
        "#   # return ngramm_forest(dcts, start)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "r1nBvTxHPT62"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tail = [\"he\", \"lost\", \"a\"]\n",
        "# for i in range(5):\n",
        "#   next = ngramm_forest(d, start=tail)\n",
        "#   print(next)\n",
        "#   tail = [*tail[1:], next]"
      ],
      "metadata": {
        "id": "916K-vlJUCFf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEsBcByCQVC_"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tail = [\"it\", \"was\", \"a\"]\n",
        "# b = np.array(sorted(d[0][tuple(tail)].items(), key=lambda x: x[1], reverse=True)[:3])\n",
        "\n",
        "# a = []\n",
        "# st = set(b[:, 0])\n",
        "# for snt in snts:\n",
        "#   for i in range(3, len(snt)):\n",
        "#     if snt[i] in st and tail[0] != snt[i-3]:\n",
        "#       a.append([*model.wv[snt[i-3]],\n",
        "#               len(snt[i-3]),\n",
        "#               *model.wv[snt[i-2]],\n",
        "#               len(snt[i-2]),\n",
        "#               *model.wv[snt[i-1]],\n",
        "#               len(snt[i-1]),\n",
        "#               i,\n",
        "#               snt[i]])"
      ],
      "metadata": {
        "id": "cCZFF6FEaGmJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len([*model.wv[snt[i-3]],\n",
        "#               len(snt[i-3]),\n",
        "#               *model.wv[snt[i-2]],\n",
        "#               len(snt[i-2]),\n",
        "#               *model.wv[snt[i-1]],\n",
        "#               len(snt[i-1]),\n",
        "#               i,\n",
        "#               snt[i]])"
      ],
      "metadata": {
        "id": "9FVFtLKIICmT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1IEyvhRHGtJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# le = LabelEncoder()\n",
        "# df = pd.DataFrame(a)\n",
        "\n",
        "# X = df.drop(columns=[304])\n",
        "# y = df[304]\n",
        "# le.fit(y)\n",
        "# y = le.transform(y)\n",
        "# print(y)\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "# forest = RandomForestClassifier(max_depth=20, random_state=0, n_estimators=10)\n",
        "\n",
        "# forest.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "kf7-uvvEu4DE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score\n",
        "# # test_ML(forest)\n",
        "# # forest.predict(X.iloc[:2, :])\n",
        "# y_pred = forest.predict(X_test)\n",
        "# accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "ldgE4In_wIW8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwrO4yT11s6h"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# le.inverse_transform(forest.predict([[*model.wv[tail[0]],\n",
        "#               len(tail[0]),\n",
        "#               *model.wv[tail[1]],\n",
        "#               len(tail[1]),\n",
        "#               *model.wv[tail[2]],\n",
        "#               len(tail[2]),\n",
        "#               4]]))"
      ],
      "metadata": {
        "id": "7GIPzxuy1ZM7"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CKfSOXgD3F7A"
      },
      "outputs": [],
      "source": [
        "# a = []\n",
        "# # np.random.choice(sentences, size=10)\n",
        "# for snt in snts[:1000]:\n",
        "#   n = len(snt)\n",
        "#   # print(snt)\n",
        "#   for i in range(3, n):\n",
        "#     a.append([*model.wv[snt[i-3]],\n",
        "#               len(snt[i-3]),\n",
        "#               *model.wv[snt[i-2]],\n",
        "#               len(snt[i-2]),\n",
        "#               *model.wv[snt[i-1]],\n",
        "#               len(snt[i-1]),\n",
        "#               i,\n",
        "#               *model.wv[snt[i]]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWDkusqyUfIJ"
      },
      "execution_count": 48,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyxNzWUx85XzVKxy7X+jZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15e682140e2246a981c511a98888a511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0350b389411742e596630d6ae76796dd",
              "IPY_MODEL_823820d8f1a542e3a840d66d783d2625",
              "IPY_MODEL_2a1566ad45d54671bb951ac904bffa64"
            ],
            "layout": "IPY_MODEL_2c52950500f949f69bb62e8f2094520a"
          }
        },
        "0350b389411742e596630d6ae76796dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f838fe1fd7ad4757a95b9d1ec4d0603f",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbb5739e5d843f680e21a135d790250",
            "value": "100%"
          }
        },
        "823820d8f1a542e3a840d66d783d2625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b6892c06956434181e6fb46d64a3b0d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff42a1b09a1745e1940720d06360479e",
            "value": 1
          }
        },
        "2a1566ad45d54671bb951ac904bffa64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cf913ef11b472d9b64cf6a813905dc",
            "placeholder": "​",
            "style": "IPY_MODEL_9864e97ab1fb453a90bbeb03afa51154",
            "value": " 1/1 [00:00&lt;00:00, 18.16it/s]"
          }
        },
        "2c52950500f949f69bb62e8f2094520a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f838fe1fd7ad4757a95b9d1ec4d0603f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbb5739e5d843f680e21a135d790250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b6892c06956434181e6fb46d64a3b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff42a1b09a1745e1940720d06360479e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0cf913ef11b472d9b64cf6a813905dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9864e97ab1fb453a90bbeb03afa51154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}